
# Veridion ML Insurance Classifier

Acest proiect reprezintÄƒ soluÈ›ia mea pentru challenge-ul tehnic Veridion â€“ task-ul #2: clasificarea companiilor Ã®n funcÈ›ie de o taxonomie din industria asigurÄƒrilor.

## ğŸ” Scopul proiectului
Clasificarea automatÄƒ a companiilor Ã®ntr-una sau mai multe etichete relevante dintr-o taxonomie staticÄƒ. Pe baza descrierii, tag-urilor È™i clasificÄƒrilor oferite, modelul Ã®nvaÈ›Äƒ sÄƒ mapeze fiecare companie la niÈ™e economice specializate.
Trebuie sÄƒ dezvolt un model de clasificare care, pornind de la datele despre companii (descriere, taguri, sector, categorie, niÈ™Äƒ), sÄƒ atribuie una sau mai multe etichete relevante dintr-o taxonomie fixÄƒ, specificÄƒ domeniului de asigurÄƒri.

**IMPORTANT** !!! 

****Aceasta este doar o schita a proietului, pentru a intelege in totalitate cum am gandit si cum am incercat sa rezolv accest task va rog sa va uitati peste documentatie.**
**
## ğŸ—‚ Structura proiectului
```
veridion_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ ml_insurance_challenge.csv           # setul de date original
â”‚   â”œâ”€â”€ insurance_taxonomy.xlsx              # taxonomia fixÄƒ (etichetare)
â”‚   â””â”€â”€ processed_data.csv                   # datele preprocesate
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_eda_raw.ipynb                     # EDA pe date brute
â”‚   â””â”€â”€ 01_eda_explorare.ipynb               # EDA pe date prelucrate
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py                       # script de preprocesare
â”‚   â”œâ”€â”€ model_training.py                    # antrenarea modelului (urmeazÄƒ)
â”‚   â””â”€â”€ utils.py                             # funcÈ›ii auxiliare (dacÄƒ e nevoie)
â””â”€â”€ README.md
```

## âš™ï¸ Stack tehnologic
- Python (pandas, scikit-learn)
- Jupyter Notebooks
- VSCode 
- CSV + Excel (.xlsx)

## ğŸ”§ PaÈ™i parcurÈ™i
**1. Explorare iniÈ›ialÄƒ a datelor brute**

- `ml_insurance_challenge.csv` â€” 9494 companii cu:
  - `description` (text liber),
  - `business_tags` (cuvinte-cheie),
  - `sector`, `category`, `niche`.
- `insurance_taxonomy.xlsx` â€” 220 etichete specializate care definesc taxonomia de clasificare.
DeÈ™i sector, category È™i niche sunt informative si usor de inteles pentru un om, din perspectivÄƒ de ML acestea au o cardinalitate mare È™i oferÄƒ context limitat faÈ›Äƒ de description È™i tags, care conÈ›in semnale semantice mai bogate. 
**2. Preprocesare textualÄƒ a coloanelor:**
  RealizatÄƒ prin `data_loader.py`. PaÈ™ii principali:

- curÄƒÈ›area textelor din `description`, `tags`, `category`, `niche`;
- conversia tag-urilor Ã®n È™iruri utilizabile (list â†’ string);
- completarea valorilor lipsÄƒ;
- crearea unei coloane `full_profile` = input standardizat pentru clasificare.

description_clean: textul descriptiv este convertit la lowercase, golurile sunt completate cu È™iruri goale, iar caracterele speciale sunt eliminate pentru a-l pregÄƒti pentru vectorizare (TF-IDF, embeddings etc.).

tags_clean: lista de business_tags este convertitÄƒ din format JSON Ã®ntr-un È™ir unificat de cuvinte-cheie relevante, cu spaÈ›iile Ã®nlocuite de _, pentru a fi compatibile cu modelele de NLP.

full_profile: cÃ¢mp compus care concateneazÄƒ description_clean, tags_clean, category È™i niche â€” oferind un rezumat semantic complet per companie, utilizat drept input principal Ã®n clasificare.

****3. Explorare date noi (EDA) ****
    Salvare fiÈ™ier procesat
    EDA pe datele prelucrate (distribuÈ›ii, lipsuri, patternuri) realizata in jupyter notebook
    Detalii Ã®n:
- `00_eda_raw.ipynb`: analiza iniÈ›ialÄƒ pe datele brute.
- `01_eda_explorare.ipynb`: analizÄƒ pe `processed_data.csv`.
**4. Crearea setului de antrenare**
Ãn aceastÄƒ etapÄƒ, am generat automat etichete de antrenament pentru fiecare companie prin mÄƒsurarea similaritÄƒÈ›ii semantice Ã®ntre profilul textual (full_profile) È™i descrierile din taxonomia de etichete. Folosind TF-IDF È™i cosine similarity, am atribuit fiecÄƒrei companii cele mai apropiate 3 etichete, salvate Ã®ntr-un fiÈ™ier annotated_training_set.csv ce va fi folosit pentru antrenarea modelului.

IniÈ›ial, am explorat o abordare semi-automatÄƒ de adnotare a unui subset de date folosind un Jupyter Notebook (02_annotation_tool.ipynb). AceastÄƒ metodÄƒ presupunea generarea unor sugestii simple pe baza unor reguli logice È™i completarea manualÄƒ a etichetelor pentru fiecare companie. Cu toate acestea, metoda s-a dovedit a fi incompletÄƒ È™i dificil de scalat, necesitÃ¢nd un efort substanÈ›ial pentru adnotare manualÄƒ È™i neacoperind suficientÄƒ diversitate semanticÄƒ.

Din acest motiv, am optat ulterior pentru o abordare complet automatÄƒ, mai robustÄƒ È™i scalabilÄƒ, folosind tehnici de procesare a limbajului natural (TF-IDF + cosine similarity). AceastÄƒ metodÄƒ permite etichetarea Ã®ntregului set de companii, bazÃ¢ndu-se pe gradul de asemÄƒnare semanticÄƒ dintre profilul textual al companiei È™i descrierile etichetelor din taxonomie. Astfel, am obÈ›inut un set adnotat realist, coerent È™i pregÄƒtit pentru antrenarea unui model de clasificare multi-label.
PaÈ™ii parcurÈ™i in aceasta etapa:
1.	Crearea unui fiÈ™ier de taxonomie extinsÄƒ (insurance_taxonomy_enhanced.csv)
FiÈ™ierul original (insurance_taxonomy.csv) conÈ›inea doar o listÄƒ de etichete (label). Am generat automat o coloanÄƒ description pentru fiecare etichetÄƒ, oferind context semantic suplimentar. Aceste descrieri au fost create cu ajutorul unui script Python care a aplicat reguli semantice simple pe baza conÈ›inutului textual al fiecÄƒrui label.
2.	Vectorizarea textelor
Am aplicat TF-IDF vectorization atÃ¢t asupra cÃ¢mpului full_profile din fiÈ™ierul cu companii (processed_data.csv), cÃ¢t È™i asupra descrierilor din taxonomie.
3.	Calculul similaritÄƒÈ›ii
Am folosit cosine similarity pentru a mÄƒsura asemÄƒnarea semanticÄƒ dintre fiecare companie È™i toate descrierile etichetelor.
4.	Selectarea etichetelor cele mai probabile
Pentru fiecare companie, au fost selectate cele mai apropiate 3 etichete (cu scoruri de similaritate cele mai mari) È™i salvate Ã®ntr-o coloanÄƒ selected_labels.
5.	Generarea fiÈ™ierului annotated_training_set.csv
Acest fiÈ™ier conÈ›ine cÃ¢mpurile full_profile È™i selected_labels È™i va fi folosit Ã®n etapa urmÄƒtoare pentru antrenarea modelului de clasificare.

**5. Construirea È™i antrenarea modelului**
DupÄƒ generarea fiÈ™ierului annotated_training_set.csv, am constatat cÄƒ datele brute conÈ›ineau peste 200 de etichete, dintre care multe erau extrem de rare. Acest lucru a dus la rezultate slabe pentru Logistic Regression È™i Random Forest, cu valori 0 la precision È™i recall pentru multe etichete. Pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a, am decis sÄƒ pÄƒstrÄƒm doar cele mai frecvente 50 de etichete È™i sÄƒ reconstruim setul de antrenare (annotated_training_set_filtered-regresie.csv).

Pe baza acestuia, am testat trei clasificatori multi-label: Logistic Regression, LinearSVC È™i Random Forest. Am vectorizat textul folosind TF-IDF È™i am binarizat etichetele cu MultiLabelBinarizer. Rezultatele obÈ›inute au fost:

LinearSVC: cele mai bune scoruri generale (F1-weighted: 0.53)

Random Forest: performanÈ›Äƒ rezonabilÄƒ dupÄƒ filtrarea etichetelor (F1-weighted: 0.50)

Logistic Regression: rezultate acceptabile, folosit ca variantÄƒ de backup (F1-weighted: 0.52)

Am pÄƒstrat LinearSVC ca model principal pentru testare ulterioarÄƒ, datoritÄƒ echilibrului bun Ã®ntre precizie È™i acoperire, fÄƒrÄƒ ajustÄƒri suplimentare.

**6. Testarea modelelor È™i concluzii finale**
Ãn etapa finalÄƒ, modelele antrenate anterior au fost aplicate pe Ã®ntreg setul de 9494 companii pentru a prezice una sau mai multe etichete de asigurÄƒri.

Linear SVC a fost singurul model antrenat pe toate cele 220 de etichete È™i este considerat modelul principal al soluÈ›iei.

Logistic Regression È™i Random Forest au fost antrenate doar pe top 50 cele mai frecvente etichete È™i au fost utilizate Ã®n scop comparativ.

Rezultate:
Linear SVC a generat predicÈ›ii complete pentru toate companiile, cu o estimare de 56.1% predicÈ›ii acceptabile (conform analizei manuale È™i comparative).

Logistic Regression: 4488 predicÈ›ii non-goale (acoperire 47.2%)

Random Forest: 1747 predicÈ›ii non-goale (acoperire 18.4%)

Suprapunere parÈ›ialÄƒ Ã®ntre modele:

987 companii cu etichete comune Ã®ntre Linear SVC È™i Random Forest

683 Ã®ntre Linear SVC È™i Logistic Regression

Linear SVC rÄƒmÃ¢ne cea mai robustÄƒ È™i completÄƒ soluÈ›ie, capabilÄƒ sÄƒ generalizeze eficient pe tot setul de date.

**6. Posibiile Imbunatatiri**
Sugestii de Ã®mbunÄƒtÄƒÈ›ire
Trecerea de la TF-IDF la BERT: Modelele Transformer precum BERT pot Ã®nÈ›elege mai bine contextul semantic al descrierilor companiilor. Folosirea unui model precum all-MiniLM-L6-v2 ar putea creÈ™te considerabil acurateÈ›ea predicÈ›iilor.

Praguri adaptative pentru etichete: Ãn loc de un scor fix (ex: 0.5) pentru toate clasele, se pot optimiza praguri individuale pentru fiecare etichetÄƒ, crescÃ¢nd precizia È™i reducÃ¢nd etichetele eronate.

Etichetare umanÄƒ pe subset: Adnotarea manualÄƒ a unui eÈ™antion de companii ar permite o evaluare mai realistÄƒ a modelelor È™i Ã®mbunÄƒtÄƒÈ›irea ulterioarÄƒ a setului de antrenament.

Scalabilitate cu Apache Spark: Ãn cazul unor seturi de date la scarÄƒ industrialÄƒ (milioane de companii), o implementare distribuitÄƒ cu Apache Spark ar permite procesarea paralelÄƒ a datelor text, antrenarea mai rapidÄƒ a modelelor È™i aplicarea scalabilÄƒ a predicÈ›iilor.

## ğŸ§  ObservaÈ›ii
- Etichetarea nu are un ground truth clar â†’ validare prin analizÄƒ logicÄƒ
 Etichetele sunt foarte specializate (ex: agriculturÄƒ, mediu, servicii).
- Task-ul nu e o clasificare simplÄƒ (Life vs. P&C), ci un mapping cÄƒtre niÈ™e complexe.
- Provocarea constÄƒ Ã®n extragerea de semnale relevante din descrieri + taguri.
- Se acceptÄƒ clasificare multi-label (compania poate primi mai multe etichete)
- SoluÈ›ia trebuie sÄƒ fie clar explicatÄƒ È™i scalabilÄƒ conceptual

## ğŸ“Œ Status: Ã®n desfÄƒÈ™urare
